# Configuration Guide

## Server Configuration

The server supports multiple configuration options that can be supplied as environment variables and/or configuration files.

### Server Environment Variables

| Variable | Description | Required | Default Value |
|----------|-------------|----------|---------------|
|`JWT_SECRET_KEY`|Secret key used by Flask to encode and decode JWTs|✓||
|`SQLALCHEMY_DATABASE_URI`|Database connection URI, for example `sqlite:///sqlite.db` or `postgresql://sidekick_user:sidekick_password@127.0.0.1/sidekick_db`|✓||
|`OPENAI_API_KEY`|Key used to authenticate with OpenAI's API|✓||
|`OPENAI_BASE_URL`|Base URL for OpenAI API|✓|`https://api.openai.com/v1`|
|`SIDEKICK_SERVER_PORT`|Port for the Sidekick Server to run on when using `run.py`|✓|`5000`|
|`SIDEKICK_WEBUI_BASE_URL`|Base URL for the Sidekick Web UI service|✓|`http://localhost:8081`|
|`SIDEKICK_UTILITY_MODEL`|Model used for utility functions such as naming chats and notes and AI Help. If you are running offline, for example with ollama models, you would change this|||
|`OIDC_WELL_KNOWN_URL`|The OIDC provider's well-known URL, required for OIDC authentication support|||
|`OIDC_TOKEN_ENDPOINT`|The OIDC provider's token endpoint, used for handling OIDC logout|||
|`OIDC_REDIRECT_URL`|Where the OIDC provider should redirect to after successful login.|||
|`OIDC_CLIENT_ID`|Client ID used for authenticating with OIDC provider|||
|`OIDC_CLIENT_SECRET`|Client secret used for authenticating with OIDC provider|||
|`LOG_LEVEL`|Minimum urgency of logs to write to standard out. Supported values: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'.||`ERROR`|
|`FLASK_DEBUG`|Whether or not to run the Flask app in debug mode. Supported values: 'True', 'False'.|||

### System settings

System settings can be used to customise specific parts of the application by editing the content of files in the `server/system_settings` directory. Some of these can also be edited by the admin user via the Admin page.

## Database Configuration

The server uses SQLAlchemy to connect to a RDBMS system, ideally SQLite or Postgres. Set the database connection string via the SQLALCHEMY_DATABASE_URI environment variable.

The app also uses Flask-Migrate to generate and apply database migrations. Migrations are stored in the `server/migrations/` directory. Migrations are generated by making changes to `server/models.py` and running the command `pipenv run flask db migrate -m "<Migration Description>"`. This will create a new migration in the `server/migrations/` directory. The app will automatically attempt to apply a migration when first starting up if the database engine is postgresql. Alternatively, manually upgrading the database with the latest migrations can be done by running `pipenv run flask db upgrade`.

## User settings

### Default Settings

The server has a set of default settings that are applied to all users. These are copied to new users when they are created and they are merged into existing user settings when they login. This means that existing user settings are not overwritten, but new types of settings can be added elsewhere in the json structure to support new release features.

The default settings are stored in the `server/default_settings` folder. There is a separate json file per component that has settings.

#### model_settings.json

`server/default_settings/model_settings.json` contains the default settings for the model settings component. This includes the list of options available for model proviers, models, and settings per model including allowed values or ranges. It also includes the default values for the model settings for each model.

The file is structured as follows:

```json
{
    "version": "0",
    "model_settings": {
        "providers": {
            "OpenAI": {
                "models": {
                    "gpt-4o": {
                        "temperature": 0.7,
                        "topP": 1,
                        "frequencyPenalty": 0,
                        "presencePenalty": 0,
                        "contextTokenSize": 128000,
                        "systemMessage": "You are a helpful advisor.",
                        "notes": "Points to the latest version of the gpt-4o (Omni) model. OpenAI's high-intelligence flagship model for complex, multi-step tasks. GPT-4o is cheaper and faster than GPT-4 Turbo."
                    },
                    "gpt-4o-mini": {
                        // details
                    }
                    // more models
                },
                "default": "gpt-4o",
                "releaseUpdates": {
                    "modelUpdate": {
                        "message": "Your default AI model has been set to gpt-4o, which is OpenAI's high-intelligence flagship model for complex, multi-step tasks. It's faster and lower cost than gpt4-turbo. Other models are available in Model Settings. For example, gpt-4o-mini is even faster and suitable for most simple tasks.",
                        "model": "gpt-4o",
                        "pending": true
                    }
                }
            },
            "Ollama": {
                "models": {
                    "llama3": {
                        // details
                    },
                    "falcon:40b": {
                        // details
                    },
                    "mistral": {
                        // details
                    }
                    // more models
                },
                "default": "llama3"
            }
        },
        "default": "OpenAI"
    },
    "sliders": {
        "temperature": {
            // details
        },
        "top_p": {
            // details
        },
        "presence_penalty": {
            // details
        },
        "frequency_penalty": {
            // details
        }
    }
}
```

##### Model Updates

As model providers update their models with better ones or deprecate older ones, it sometimes will be necessary to override the users default model. This can be done by adding a new entry to the `releaseUpdates` field in the `model_settings.json` file. For example, the following entry will set the default model to `gpt-4o` and mark it as pending so that the next time the user logs on the system will automatically change their currently selected model to this and save it as their default. A notification window will pop up displaying the message provided in the modelUpdate.

Example of a model update:

```json
                "releaseUpdates": {
                    "modelUpdate": {
                        "message": "Your default AI model has been set to gpt-4o, which is OpenAI's high-intelligence flagship model for complex, multi-step tasks. It's faster and lower cost than gpt4-turbo. Other models are available in Model Settings. For example, gpt-4o-mini is even faster and suitable for most simple tasks.",
                        "model": "gpt-4o",
                        "pending": true
                    }
                }
```